---
title: Validation of trajectory sampler
output: rmarkdown::github_document
---

```{r message=FALSE}
library(tidyverse)
library(plotly)
source("../../scripts/trajProcessing.R")
```

This document describes several validation tests that have been performed
on the trajectory sampling system of bdmm-prime. This system allows for
post-MCMC sampling of birth-death trajectories.  Ideally it should work
for any of the models that bdmm-prime itself supports, including models
with

* multi-$\rho$-sampling,
* sampled ancestors (generated by either $\psi$- or $\rho$-sampling events),
* multiple types.

To support the sampling of trajectories for multiple types, the method
relies on the stochastic mapping algorithm already implemented in bdmm-prime.


# Validation strategies

We will use two main strategies for validation of the trajectory sampler:

1. comparison of the tree probability computed by the importance sampler
   with a value computed by integrating the KBE, and
2. comparison of the trajectories sampled conditional on each of an ensemble
   of simulated trees with the distribution of unconditioned trajetories.
   
The first strategy is straightforward for uncoloured trajectories, as the
BDMM-prime tree prior can be used to provide the comparision probability.
For the case of coloured trajectories, we'll instead rely on an independent
R implementation of the KBE integration and use this validation only for
specific small coloured trees (as the integration procedure is hard-coded).

The second strategy is in some ways superior, as it directly tests the validity
of the conditional trajectory distribution sampled by the algorithm, and is
based on the simple fact that

$$P(\eta|\theta) = \sum_{\tau}P(\eta|\tau,\theta)P(\tau|\theta).$$

However it is slightly harder to detect deviations from the truth, as
it requires comparing two distributions of highly multi-dimensional
samples.


# Single-type trajectories

For the single-typed models we will perform both kinds of validation.

In each case we will simulate 1000 trees and trajectories under a BD
model, then use the conditional trajectory sampler to produce a second
set of 1000 trees under the same distribution.  We will then these
two distributions, as well as the tree probability estimates for each
of the simulated trees.

## Simple validation

To begin, let's look at a very simple single-type birth-death-sampling model with the following parameters:

* $\lambda = 2$
* $\mu = 1$
* $\psi = 0.5$
* $T = 5$

where $T$ is the length of the trajectory simulation.

First we run the simulations and sample the trajectories:
```{bash results=FALSE, eval=FALSE}
pushd single_type
java -jar ../../../out/artifacts/bdmm_prime_jar/bdmm-prime.jar \
     -overwrite traj_and_tree_simulator_1type.xml 
java -jar ../../../out/artifacts/bdmm_prime_jar/bdmm-prime.jar \
     -overwrite traj_inference_1type.xml 
popd
```

Now we can load in the data and compare the probability estimates
generated as part of the conditioned trajectory sampling with those
computed using bdmm-prime's KBE integration (analytical in the
single-type case):
```{r message=FALSE}
dat <- read_tsv("single_type/traj_inference_1type.log")
ggplot(dat, aes(x=logProb, y=logProbEst)) + geom_abline(col='red') + geom_point(col='blue')
```

These results look quite convincing. How about when we focus on the differences?
```{r }
ggplot(dat) + geom_point(aes(Sample, logProb-logProbEst))
```

Thus it looks like the tree probability estimates generated by the
particle filter are within 0.5 log units of the true values.  Given
that the probability densities of these trees are as small as $10^{-750}$,
this is extremely close agreement, providing a strong indication that
the particle filter is correctly implemented for this model type.

Now let's look at the distribution of the actual trajectories.

```{r message=FALSE}
trajTrue <- loadTrajectories("single_type/traj_and_tree_simulator_1type.traj")
trajSamp <- loadTrajectories("single_type/traj_inference_1type.traj")

times <- seq(0, 5, length.out=51)

traj <- bind_rows(gridTrajectories(trajTrue$states, times) %>% mutate(ensemble="Original"),
                  gridTrajectories(trajSamp$states, times) %>% mutate(ensemble="Filter"))
```

```{r warning=FALSE, message=FALSE}
ggplot(traj %>%
       group_by(time, ensemble) %>%
       summarize(mean=mean(N), low=quantile(N, 0.25), high=quantile(N, 0.75))) +
    geom_ribbon(aes(time, ymin=low, ymax=high, fill=ensemble, color=ensemble), alpha=0.5) +
    geom_line(aes(time, mean, color=ensemble)) +
    ylab("Population sizes") +
    scale_y_log10()
```

Apart from noise due to the finite number of samples, these two
distributions appear to be equivalent indicating that, for this model,
the implementation is correct.


## Sampled-ancestor validation

Now let's consider the same setup, but including sampling without removal:

* $\lambda = 2$
* $\mu = 1$
* $\psi = 0.5$
* $T = 5$
* $r = 0.5$

Again we run the simulations and sample the trajectories:
```{bash results=FALSE, eval=FALSE}
pushd single_type
java -jar ../../../out/artifacts/bdmm_prime_jar/bdmm-prime.jar \
     -overwrite traj_and_tree_simulator_1type_SA.xml 
java -jar ../../../out/artifacts/bdmm_prime_jar/bdmm-prime.jar \
     -overwrite traj_inference_1type_SA.xml 
popd
```

Once more we can compare the tree prior estimates generated by the particle
filter with those generated by numerical integration.
```{r message=FALSE}
dat <- read_tsv("single_type/traj_inference_1type_SA.log")
ggplot(dat, aes(x=logProb, y=logProbEst)) + geom_abline(col='red') + geom_point(col='blue')
```
Again we see extremely close agreement.  The absolute differences are also tiny:
```{r }
ggplot(dat) + geom_point(aes(Sample, logProb-logProbEst))
```

## $\rho$-sampling validation (no sampled-ancestors)

* $\lambda = 2$
* $\mu = 1$
* $\psi = 0.0$
* $T = 5$
* $r = 1.0$
* $\rho = 0.5$ (at time 2.5)


Comparing the tree prior estimates generated by the particle
filter with those generated by numerical integration gives:
```{r message=FALSE}
dat <- read_tsv("single_type/traj_inference_1type_rho.log")
ggplot(dat, aes(x=logProb, y=logProbEst)) + geom_abline(col='red') + geom_point(col='blue')
```
Again we see very little deviation, even in absolute terms:
```{r }
ggplot(dat) + geom_point(aes(logProb, logProb-logProbEst))
```

The actual trajectories look like this:
```{r }
trajTrue <- loadTrajectories("single_type/traj_and_tree_simulator_1type_rho.traj")

trajSamp <- loadTrajectories("single_type/traj_inference_1type_rho.traj")
times <- seq(0, 5, length.out=51)
traj <- bind_rows(gridTrajectories(trajTrue$states, times) %>% mutate(ensemble="Original"),
                  gridTrajectories(trajSamp$states, times) %>% mutate(ensemble="Filter"))
```

```{r warning=FALSE, message=FALSE}
ggplot(traj %>%
       group_by(time, ensemble) %>%
       summarize(mean=mean(N), low=quantile(N, 0.25), high=quantile(N, 0.75))) +
    geom_ribbon(aes(time, ymin=low, ymax=high, fill=ensemble, color=ensemble), alpha=0.5) +
    geom_line(aes(time, mean, color=ensemble)) +
    ylab("Population sizes") +
    scale_y_log10()
```

## $\rho$-sampling validation (with sampled-ancestors)

* $\lambda = 2$
* $\mu = 1$
* $\psi = 0.0$
* $T = 5$
* $r = 0.5$
* $\rho = 0.5$ (at time 2.5)

Comparing the tree prior estimates generated by the particle
filter with those generated by numerical integration gives:
```{r message=FALSE}
dat <- read_tsv("single_type/traj_inference_1type_rhoSA.log")
ggplot(dat, aes(x=logProb, y=logProbEst)) + geom_abline(col='red') + geom_point(col='blue')
```
Again we see very little deviation, even in absolute terms:
```{r }
ggplot(dat) + geom_point(aes(logProb, logProb-logProbEst))
```


The actual trajectories look like this:
```{r }
trajTrue <- loadTrajectories("single_type/traj_and_tree_simulator_1type_rhoSA.traj")

trajSamp <- loadTrajectories("single_type/traj_inference_1type_rhoSA.traj")

times <- seq(0, 5, length.out=51)
traj <- bind_rows(gridTrajectories(trajTrue$states, times) %>% mutate(ensemble="Original"),
                  gridTrajectories(trajSamp$states, times) %>% mutate(ensemble="Filter"))
```

```{r warning=FALSE, message=FALSE}
ggplot(traj %>%
       group_by(time, ensemble) %>%
       summarize(mean=mean(N), low=quantile(N, 0.25), high=quantile(N, 0.75))) +
    geom_ribbon(aes(time, ymin=low, ymax=high, fill=ensemble, color=ensemble), alpha=0.5) +
    geom_line(aes(time, mean, color=ensemble)) +
    ylab("Population sizes") #+
    ## scale_y_log10()
```



# Multi-type trajectories

In this section we adopt the same validation approaches as in the
previous section, but emphasize the trajectory distribution
comparison.

## Simple sampling strategy validation

Our first multi-type model will consist of only 2 types, with the following parameters:

* $\lambda_i = 2$
* $\mu_i = 1$
* $\psi_i = 0.5$

for $i \in \{1,2\}$, and

* $M = [0, 0.5; 0.1, 0]$.

We use another pair of XML files to run these analyses:
```{bash results=FALSE, eval=FALSE}
pushd multi_type
java -jar ../../../out/artifacts/bdmm_prime_jar/bdmm-prime.jar \
     -overwrite traj_and_tree_simulator_2types.xml 
java -jar ../../../out/artifacts/bdmm_prime_jar/bdmm-prime.jar \
     -overwrite traj_inference_2types.xml 
popd
```

We then use the following to load an process the trajectories:
```{r message=FALSE}
source("../../scripts/trajProcessing.R")

trajTrue <- loadTrajectories("multi_type/traj_and_tree_simulator_2types.traj")

trajSamp <- loadTrajectories("multi_type/traj_inference_2types.traj")

trajSampTL <- loadTrajectories("multi_type/traj_inference_2types.TL.traj")

times <- seq(0, 5, length.out=51)

traj <- bind_rows(gridTrajectories(trajTrue$states, times) %>% mutate(ensemble="Original"),
                  gridTrajectories(trajSamp$states, times) %>% mutate(ensemble="Filter"),
                  gridTrajectories(trajSampTL$states, times) %>% mutate(ensemble="FilterTL"))
```

Visualizing the results yields the following.

```{r warning=FALSE, message=FALSE}
ggplot(traj %>%
       ## filter(type==0) %>%
       group_by(time, ensemble, type) %>%
       summarize(mean=mean(N), low=quantile(N, 0.25), high=quantile(N, 0.75))) +
    geom_ribbon(aes(time, ymin=low, ymax=high, fill=ensemble, color=ensemble), alpha=0.25) +
    geom_line(aes(time, mean, color=ensemble)) +
    ylab("Population sizes") +
    scale_y_log10() +
    facet_grid(rows=vars(factor(type)))
```

Again we have close agreement between the two distributions.
